{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgiFzR-TVFrA"
   },
   "source": [
    "# Second Practical work\n",
    "\n",
    "* Name Student 1: Andrew Sivak\n",
    "* NIA Student 1: 100520897\n",
    "* Name Student 2:\n",
    "* NIA Student 2:\n",
    "  \n",
    "This is second practical work skeleton.\n",
    "\n",
    "It is divided in 3 parts_\n",
    "\n",
    "1.   Python module load section: load all the needed modules\n",
    "2.   Google Drive access and mounting\n",
    "3.   Host load data\n",
    "4.   GPU load\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfmxFIzPWszg"
   },
   "source": [
    "## Module load section\n",
    "We will install the pycuda module in the colaboratory environment, to combine python and CUDA in our code. Because pycuda is not available by default, this task can take a few minutes.\n",
    "\n",
    "As well we load numpy and matplotlib modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyconfig in c:\\users\\andro\\anaconda3\\lib\\site-packages (3.2.3)\n",
      "Requirement already satisfied: six in c:\\users\\andro\\appdata\\roaming\\python\\python311\\site-packages (from pyconfig) (1.16.0)\n",
      "Requirement already satisfied: pytool in c:\\users\\andro\\anaconda3\\lib\\site-packages (from pyconfig) (3.16.2)\n",
      "Requirement already satisfied: simplejson>=3.2.0 in c:\\users\\andro\\anaconda3\\lib\\site-packages (from pytool->pyconfig) (3.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement jyupiter (from versions: none)\n",
      "ERROR: No matching distribution found for jyupiter\n"
     ]
    }
   ],
   "source": [
    "!pip install jyupiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h5Q-ylEHHB2k",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycuda\n",
      "  Using cached pycuda-2023.1.tar.gz (1.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytools>=2011.2 (from pycuda)\n",
      "  Obtaining dependency information for pytools>=2011.2 from https://files.pythonhosted.org/packages/3d/4b/4cbe808b38ee25d3c3f1b1b99bde39cef43c30df64416b62e28079404d1b/pytools-2023.1.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytools-2023.1.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: appdirs>=1.4.0 in c:\\users\\andro\\anaconda3\\lib\\site-packages (from pycuda) (1.4.4)\n",
      "Collecting mako (from pycuda)\n",
      "  Obtaining dependency information for mako from https://files.pythonhosted.org/packages/24/3b/11fe92d68c6a42468ddab0cf03f454419b0788fff4e91ba46b8bebafeffd/Mako-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached Mako-1.3.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in c:\\users\\andro\\appdata\\roaming\\python\\python311\\site-packages (from pytools>=2011.2->pycuda) (3.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\andro\\anaconda3\\lib\\site-packages (from mako->pycuda) (2.1.1)\n",
      "Using cached pytools-2023.1.1-py2.py3-none-any.whl (70 kB)\n",
      "Using cached Mako-1.3.0-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml): started\n",
      "  Building wheel for pycuda (pyproject.toml): finished with status 'error'\n",
      "Failed to build pycuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for pycuda (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [137 lines of output]\n",
      "  ***************************************************************\n",
      "  *** WARNING: nvcc not in path.\n",
      "  *** May need to set CUDA_INC_DIR for installation to succeed.\n",
      "  ***************************************************************\n",
      "  *************************************************************\n",
      "  *** I have detected that you have not run configure.py.\n",
      "  *************************************************************\n",
      "  *** Additionally, no global config files were found.\n",
      "  *** I will go ahead with the default configuration.\n",
      "  *** In all likelihood, this will not work out.\n",
      "  ***\n",
      "  *** See README_SETUP.txt for more information.\n",
      "  ***\n",
      "  *** If the build does fail, just re-run configure.py with the\n",
      "  *** correct arguments, and then retry. Good luck!\n",
      "  *************************************************************\n",
      "  *** HIT Ctrl-C NOW IF THIS IS NOT WHAT YOU WANT\n",
      "  *************************************************************\n",
      "  Continuing in 10 seconds...\n",
      "  Continuing in 9 seconds...\n",
      "  Continuing in 8 seconds...\n",
      "  Continuing in 7 seconds...\n",
      "  Continuing in 6 seconds...\n",
      "  Continuing in 5 seconds...\n",
      "  Continuing in 4 seconds...\n",
      "  Continuing in 3 seconds...\n",
      "  Continuing in 2 seconds...\n",
      "  Continuing in 1 seconds...\n",
      "  C:\\Users\\andro\\AppData\\Local\\Temp\\pip-build-env-5v6lly9f\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:265: UserWarning: Unknown distribution option: 'test_requires'\n",
      "    warnings.warn(msg)\n",
      "  \n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\autoinit.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\autoprimaryctx.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\characterize.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\compiler.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\cumath.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\curandom.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\debug.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\driver.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\elementwise.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\gpuarray.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\reduction.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\scan.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\tools.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\_cluda.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\_mymako.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  copying pycuda\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\n",
      "  creating build\\lib.win-amd64-cpython-311\\pycuda\\gl\n",
      "  copying pycuda\\gl\\autoinit.py -> build\\lib.win-amd64-cpython-311\\pycuda\\gl\n",
      "  copying pycuda\\gl\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\\gl\n",
      "  creating build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\cg.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\coordinate.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\inner.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\operator.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\packeted.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\pkt_build.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  copying pycuda\\sparse\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  creating build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "  copying pycuda\\compyte\\array.py -> build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "  copying pycuda\\compyte\\dtypes.py -> build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "  copying pycuda\\compyte\\__init__.py -> build\\lib.win-amd64-cpython-311\\pycuda\\compyte\n",
      "  running egg_info\n",
      "  writing pycuda.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pycuda.egg-info\\dependency_links.txt\n",
      "  writing requirements to pycuda.egg-info\\requires.txt\n",
      "  writing top-level names to pycuda.egg-info\\top_level.txt\n",
      "  reading manifest file 'pycuda.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching 'doc\\source\\*.rst'\n",
      "  warning: no files found matching 'doc\\source\\conf.py'\n",
      "  warning: no files found matching 'doc\\source\\_static\\*.css'\n",
      "  warning: no files found matching 'doc\\source\\_templates\\*.html'\n",
      "  warning: no files found matching '*.cpp' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "  warning: no files found matching '*.html' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "  warning: no files found matching '*.inl' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "  warning: no files found matching '*.txt' under directory 'bpl-subset\\bpl_subset\\boost'\n",
      "  warning: no files found matching '*.h' under directory 'bpl-subset\\bpl_subset\\libs'\n",
      "  warning: no files found matching '*.ipp' under directory 'bpl-subset\\bpl_subset\\libs'\n",
      "  warning: no files found matching '*.pl' under directory 'bpl-subset\\bpl_subset\\libs'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'pycuda.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\andro\\AppData\\Local\\Temp\\pip-build-env-5v6lly9f\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:207: _Warning: Package 'pycuda.cuda' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pycuda.cuda' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'pycuda.cuda' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'pycuda.cuda' to be distributed and are\n",
      "          already explicitly excluding 'pycuda.cuda' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  creating build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "  copying pycuda\\cuda\\pycuda-complex-impl.hpp -> build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "  copying pycuda\\cuda\\pycuda-complex.hpp -> build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "  copying pycuda\\cuda\\pycuda-helpers.hpp -> build\\lib.win-amd64-cpython-311\\pycuda\\cuda\n",
      "  copying pycuda\\sparse\\pkt_build_cython.pyx -> build\\lib.win-amd64-cpython-311\\pycuda\\sparse\n",
      "  running build_ext\n",
      "  building '_driver' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycuda\n",
      "ERROR: Could not build wheels for pycuda, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install pycuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl4AhbSbW19W"
   },
   "source": [
    "We import the Python modules which we will use in the notebook (numpy, pycuda and time module) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TLEg2Y41HFB3",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mnumpy\u001b[39;00m  \u001b[38;5;28;01mas\u001b[39;00m  \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoinit\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m    \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SourceModule\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m  \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m  \u001b[38;5;21;01mdrv\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"
     ]
    }
   ],
   "source": [
    "import  numpy  as  np\n",
    "import  pycuda.autoinit\n",
    "from    pycuda.compiler import SourceModule\n",
    "import  pycuda.driver as  drv\n",
    "import  pycuda.gpuarray as  gpuarray\n",
    "from sys import getsizeof\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfOtyml91WNb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHsvF9qH2G_u"
   },
   "source": [
    "## Mount Google Drive and access grant\n",
    "This part could be used to access to your Google Drive Data, **ONLY IF YOU ARE USING GOOGLE COLABORATORY**. Otherwise leave commented out. \n",
    "\n",
    "For security and privacy reasons, this permission is temporally, and will be requested every time you restart the notebook. \n",
    "\n",
    "Your Google Drive will be mounted in the \"/content/drive\" folder. The first Folder will be \"My Drive\".\n",
    "\n",
    "You have to copy your images to a folder in the \"My Drive\" folder in your Google Drive.\n",
    "\n",
    "To check your available files, use the cell indicated as \"**List Files in Folder**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykYa7-u8zDzk"
   },
   "outputs": [],
   "source": [
    "# from os.path import join\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /content/drive/My\\ Drive/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RN-zy4mQzN-J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtdarelZfv7Y"
   },
   "source": [
    "## IMAGES DEFINITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follow MYDRIVE variable will be used to address where are stored the images files.\n",
    "\n",
    "Please, change it to your correct location.\n",
    "\n",
    "All the images should be refered to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEkj24AFzdqw"
   },
   "outputs": [],
   "source": [
    "MYDRIVE=\"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ9NrNYXf1Rg"
   },
   "source": [
    "We define a variable IMAGE which is constructed joining the \"MYDRIVE\" varible plus the final path to your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TAhlCjS0YPw"
   },
   "outputs": [],
   "source": [
    "IMAGE=join(MYDRIVE,HERE YOU HAVE TO WRITE THE IMAGE TO LOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVa1h0wr0fDJ"
   },
   "outputs": [],
   "source": [
    "print(\"Image to load: {0}\".format(IMAGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otUSnNLOgilw"
   },
   "source": [
    "Loads an image in a numpy variable, and show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5MbuRm_1hdQ"
   },
   "outputs": [],
   "source": [
    "image=np.array(Image.open(IMAGE))\n",
    "plt.figure()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTERS DEFINITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV8ZVagpiI97"
   },
   "source": [
    "Here we defines our sample filter masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWzJi8niPpuQ"
   },
   "outputs": [],
   "source": [
    "filter1=np.array([\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,1,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]\n",
    "])\n",
    "filter2=np.array([[0.5, 0 , -0.5]])\n",
    "filter3=np.array([[0.5],[0],[-0.5]])\n",
    "\n",
    "filter4=np.array([\n",
    "    [1,2,1],\n",
    "    [0,0,0],\n",
    "    [-1,-2,-1]\n",
    "])\n",
    "filter5=np.array([\n",
    "    [0.00078633,0.00655965,0.01330373,0.00655965,0.00078633],\n",
    "    [0.00655965,0.05472157,0.11098164,0.05472157,0.00655965],\n",
    "    [0.01330373,0.11098164,0.22508352,0.11098164,0.01330373],\n",
    "    [0.00655965,0.05472157,0.11098164,0.05472157,0.00655965],\n",
    "    [0.00078633,0.00655965,0.01330373,0.00655965,0.00078633]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhQwn2EMXDEY"
   },
   "source": [
    "## FILTER KERNEL\n",
    "\n",
    "Here you have to define your image_filter GPU kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY6Tlr-DHWU6"
   },
   "outputs": [],
   "source": [
    "kernel  =  SourceModule (\"\"\"\n",
    "__global__ void image_filter( float * src_image,          //Source GPU array floating point 32 bits,\n",
    "\t\t                      float * filter_mask,        //Filter Mask GPU array 2D floating point 32 bits\n",
    "                              float * dst_image,          //Target GPU array 2D floating point 32 bits,\n",
    "                              int NumRowsImg,             //Image Numrows,\n",
    "                              int NumColsImg,             //Int32 Image Numcolumns,\n",
    "                              int NumRowsFilter,          //Int32 Image NumRows filter mask,\n",
    "                              int NumColsFilter           //Int32 Image NumCols filter mask\n",
    "                              ) \n",
    "{ \n",
    "    //This instruction calculate in the offset in the memory data, based on the block identificator blockIdx.x\n",
    "    // YOU HAVE TO WRITE HERE YOUR FILTER KERNEL USING TILED MEMORY ALGORITHMS\n",
    "\n",
    "    //THIS CODE JUST COPY THE SOURCE IMAGE IN THE TARGET VECTOR\n",
    "    int idxY;\n",
    "    int idxX;\n",
    "    int vX;\n",
    "\n",
    "    idxY = blockIdx.y*blockDim.y+threadIdx.y; //With this we calculate the row address in target matrix\n",
    "    idxX = blockIdx.x*blockDim.x+threadIdx.x;\n",
    "    if ((idxY<NumRowsImg) && (idxX<NumColsImg)){\n",
    "      vX=idxY*NumColsImg+idxX;\n",
    "      dst_image[vX]=src_image[vX];\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovzzmuXBXYFH"
   },
   "source": [
    "And import the kernel definition to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHkXntH0H2lL"
   },
   "outputs": [],
   "source": [
    "image_filter = kernel.get_function ('image_filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8y0LIU2hOd0"
   },
   "source": [
    "## SETUP EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6NmxsN7X-02"
   },
   "source": [
    "Recover the image shape, and select the two first items (rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9aWxHFFHxzT"
   },
   "outputs": [],
   "source": [
    "image_shape=image.shape[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Txj67lrFYESV"
   },
   "source": [
    "Set block size and grid size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sayAB5iQISs8"
   },
   "outputs": [],
   "source": [
    "block_s=16\n",
    "block_size=(block_s,block_s,1)\n",
    "grid_size=(int(np.ceil(image_shape[1]/block_s)),int(np.ceil(image_shape[0]/block_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4whAEkzPhvOC"
   },
   "source": [
    "Allocates the target image memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnHTEzQXIw66"
   },
   "outputs": [],
   "source": [
    "result_image=np.zeros(image.shape,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8PcD3JeI-5K"
   },
   "outputs": [],
   "source": [
    "depth = image.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKu-1Eo7iSgz"
   },
   "source": [
    "### Select the filter mask, and upload to the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxIm7BzdN8az"
   },
   "outputs": [],
   "source": [
    "filter_mask=filter1.astype(np.float32)\n",
    "filter_mask_gpu=gpuarray.to_gpu(filter_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ8gPCW0ijld"
   },
   "source": [
    "## Prepares the execution environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdGCCI0PixrT"
   },
   "source": [
    "Allocate the temporal filtered memory layer, where will be store the filtered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qK0LgeDWU27"
   },
   "outputs": [],
   "source": [
    "filtered_image_layer_gpu = gpuarray.zeros(image_shape,np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1oLCrqAYqED"
   },
   "source": [
    "Here defines the main block.\n",
    "Walk through the layers. Copying the selected layer to temporal image_layer, upload the layer to the GPU and invokes the image_filter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvEsPtYFIUl3"
   },
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 10 -o\n",
    "for layer in range(depth):\n",
    "  image_layer = np.zeros(image_shape,dtype=np.float32) #Allocate the temporal image layer\n",
    "  image_layer=(image[:,:,layer]).astype(np.float32)    #Copy from the orignal image the selected layer into the temporal memory\n",
    "  image_layer_gpu=gpuarray.to_gpu(image_layer)         #Uploads the image layer to the GPU\n",
    "  filtered_image_layer_gpu.fill(0.0)                   #Fills with 0 the target memory in the GPU\n",
    "  image_filter(                                        #invokes the kernel\n",
    "          image_layer_gpu,\n",
    "          filter_mask_gpu,\n",
    "          filtered_image_layer_gpu,\n",
    "          np.int32(image_shape[0]),\n",
    "          np.int32(image_shape[1]),\n",
    "          np.int32(filter_mask.shape[0]),\n",
    "          np.int32(filter_mask.shape[1]),\n",
    "          block=block_size,\n",
    "          grid=grid_size\n",
    "        )\n",
    "  filtered_image_layer=filtered_image_layer_gpu.get() #Download from the GPU the filtered image\n",
    "  result_image[:,:,layer] = filtered_image_layer.astype(np.uint8) #Copy the filtered image to the final image store, \n",
    "                                                                  #casting the data type from double to uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE* The follow code fetch from the stack the exectution statistics produced by the magic metacommand %%timeit and stores it in a python variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics=_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKz2XKjBkvgR"
   },
   "source": [
    "# Show results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "en0HMjtnk8uS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnoPI5BCS9_o"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DbfqushTXBR"
   },
   "outputs": [],
   "source": [
    "print(\"Best execution time: {}\".format(statistics.best))\n",
    "print(\"Worst execution time: {}\".format(statistics.worst))\n",
    "print(\"Mean execution time: {mean} ({stdev} std dev)\".format(mean=statistics.average,stdev=statistics.stdev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SecondPracticalWork.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
